# FIAP Tech Challenge - Fase 4: Predi√ß√£o de A√ß√µes com LSTM

![Python](https://img.shields.io/badge/Python-3.12-blue?style=for-the-badge&logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.16-orange?style=for-the-badge&logo=tensorflow)
![FastAPI](https://img.shields.io/badge/FastAPI-0.111-009688?style=for-the-badge&logo=fastapi)

## üìÑ Sobre o Projeto

Este projeto corresponde √† **Fase 4** do **Tech Challenge** da P√≥s-Gradua√ß√£o em **Machine Learning Engineering** da FIAP.

O objetivo √© desenvolver uma **pipeline completa de Machine Learning (End-to-End)** para prever o **pre√ßo de fechamento** das a√ß√µes da **Petrobras (PETR4.SA)**, utilizando uma Rede Neural Recorrente do tipo **LSTM (Long Short-Term Memory)**, capaz de capturar depend√™ncias temporais em s√©ries financeiras.

O projeto prioriza **transpar√™ncia e interpretabilidade**, apresentando ao usu√°rio final n√£o apenas o valor previsto, mas tamb√©m os **indicadores t√©cnicos e macroecon√¥micos** que influenciam a decis√£o do modelo.

## üìë Tabela de Conte√∫do

- [Notebook Principal](#-notebook-principal-do-projeto)
- [Funcionalidades Principais](#-funcionalidades-principais)
- [Tecnologias Utilizadas](#Ô∏è-tecnologias-utilizadas)
- [Arquitetura da Solu√ß√£o](#-arquitetura-da-solu√ß√£o)
- [M√©tricas e Resultados](#-m√©tricas-e-resultados)
- [Estrutura de Pastas](#-estrutura-de-pastas)
- [Instala√ß√£o e Execu√ß√£o](#Ô∏è-instala√ß√£o-e-execu√ß√£o)
- [Como Acessar a Aplica√ß√£o](#como-acessar-a-aplica√ß√£o)
- [Monitoramento e Observabilidade](#-monitoramento-e-observabilidade)
- [Conclus√£o](#conclus√£o)
- [Autores](#-autores)

---

## üìì Notebook Principal do Projeto

Toda a implementa√ß√£o do modelo de *Machine Learning* com **LSTM** ‚Äî incluindo coleta de dados, pr√©-processamento, engenharia de features, treinamento, avalia√ß√£o e valida√ß√£o ‚Äî est√° documentada de forma detalhada no notebook abaixo:

‚û°Ô∏è [Acessar notebook comentado](./notebook/TC_FASE4.ipynb)

---

## üéØ Funcionalidades Principais

- **Pipeline de Dados Automatizado:**  
  Coleta dados hist√≥ricos e indicadores macroecon√¥micos, como C√¢mbio (USD/BRL), Petr√≥leo Brent, Ibovespa e Selic.

- **Engenharia de Features:**  
  C√°lculo de indicadores t√©cnicos (RSI, MACD, Bandas de Bollinger, M√©dias M√≥veis), volatilidade, retornos e correla√ß√µes com ativos externos.

- **Modelo LSTM:**  
  Rede neural treinada para prever o **Retorno Logar√≠tmico Di√°rio**, garantindo estacionariedade e maior estabilidade num√©rica.

- **Dashboard Interativo:**  
  Interface web que exibe:
  - Cota√ß√£o atual e dados de mercado (sem necessidade de entrada manual de hist√≥ricos).
  - Painel de indicadores t√©cnicos e macroecon√¥micos.
  - Explica√ß√£o da metodologia adotada.
  - Tabela com proje√ß√µes futuras de pre√ßo.

- **API RESTful:**  
  Backend desenvolvido com **FastAPI**, respons√°vel por realizar infer√™ncia e servir o modelo treinado.

---

## üõ†Ô∏è Tecnologias Utilizadas

- **Linguagem:** Python 3.12  
- **Gerenciamento de Depend√™ncias:** Poetry  
- **Machine Learning:** TensorFlow/Keras, Scikit-learn  
- **Processamento de Dados:** Pandas, NumPy, yfinance  
- **Backend:** FastAPI, Uvicorn  
- **Frontend:** HTML5, CSS3, JavaScript  
- **Containeriza√ß√£o:** Docker (pronto para deploy)

---

## üß† Arquitetura da Solu√ß√£o

1. **Coleta & Pr√©-processamento**
   - Normaliza√ß√£o dos dados com `MinMaxScaler`
   - Cria√ß√£o de janelas deslizantes (*sliding windows*) de 20 dias

2. **Modelagem com LSTM**
   - Camadas LSTM empilhadas
   - Dropout para mitiga√ß√£o de overfitting
   - Camada Dense para regress√£o

3. **Avalia√ß√£o**
   - M√©tricas utilizadas: **MAE** e **RMSE**
   - Valida√ß√£o com os √∫ltimos 5% do conjunto de dados

4. **Persist√™ncia**
   - Modelo salvo no formato `.keras`
   - Scalers serializados em `.pkl`

5. **Infer√™ncia via API**
   - Endpoint `/api/predict`
   - Coleta autom√°tica dos dados mais recentes
   - Retorno da previs√£o convertida para o valor real em reais (R$)

---

## üìä M√©tricas e Resultados

- **Lookback:** 20 dias  
- **Target:** Retorno Logar√≠tmico Di√°rio  
- **Feature Engineering:** Sazonalidade (seno/cosseno) e volatilidade

---

## üìÇ Estrutura de Pastas

```text
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ api
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client          # Frontend (HTML/CSS/JS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ endpoints       # Rotas da API (Predict)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas         # Modelos Pydantic (Request/Response)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services        # L√≥gica de ML e Coleta de Dados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py         # Entrypoint da aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ models              # Arquivos bin√°rios (.keras, .pkl)
‚îÇ   ‚îî‚îÄ‚îÄ notebooks           # Jupyter Notebooks de estudo e treino
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ README.md
```

## ‚öôÔ∏è Instala√ß√£o e Execu√ß√£o

Siga os passos abaixo para executar o projeto localmente.

### Pr√©-requisitos
-   [Git](https://git-scm.com/)
-   [Docker](https://www.docker.com/products/docker-desktop/)
-   [Python 3.12](https://www.python.org/) exatamente esta vers√£o para compatibilidade com o treino do modelo
-   [Poetry](https://python-poetry.org/)


### Clone o reposit√≥rio e altere para o caminho raiz do projeto:
```bash
git clone https://github.com/marciojolima/tc_fiap_fase4.git
cd tc_fiap_fase4
```
### Op√ß√£o: Poetry

Para executar a API localmente utilizando Poetry.

Certifique-se que o prompt esteja na pasta raiz do projeto

**Instale as depend√™ncias:**
```bash
poetry install
```

**Inicie o servidor da API:**
```bash
poetry run uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Op√ß√£o: Pip

Certifique-se que o prompt esteja na pasta raiz do projeto

1.  **Crie um ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate
```

2.  **Instale as depend√™ncias:**
```bash
pip install -r requirements.txt
```

3.  **Instale o projeto:**
```bash
pip install -e .
```

4.  **Inicie o servidor da API:**
```bash
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Op√ß√£o: Docker

Certifique-se que o prompt esteja na pasta raiz do projeto

1.  **Inicie o container**
```bash
docker compose up --build
```

2.  **Abra o navegador e digite na barra de endere√ßos**
```bash
http://localhost:8000
```

---

## üìà Monitoramento e Observabilidade

Para garantir a confiabilidade e escalabilidade do modelo em produ√ß√£o, o projeto implementa uma stack completa de monitoramento baseada em **Prometheus** (coleta de m√©tricas) e **Grafana** (visualiza√ß√£o).

A solu√ß√£o monitora tanto a sa√∫de da infraestrutura (lat√™ncia, throughput) quanto a performance do modelo de Machine Learning (drift de pre√ßo, confian√ßa e vi√©s).

### üõ†Ô∏è Acessando a Stack de Monitoramento

Uma vez que os containers estejam rodando (`docker-compose up`), os servi√ßos estar√£o dispon√≠veis nas seguintes portas:

| Servi√ßo | URL | Descri√ß√£o | Credenciais Padr√£o |
| :--- | :--- | :--- | :--- |
| **API Swagger** | `http://localhost:8000/docs` | Interface para testar o modelo e gerar tr√°fego. | N/A |
| **Prometheus** | `http://localhost:9090` | Banco de dados de s√©ries temporais e explorador de m√©tricas. | N/A |
| **Grafana** | `http://localhost:3000` | Dashboards visuais para an√°lise de MLOps. | `admin` / `admin` |

---

### üöÄ Guia de Valida√ß√£o do Monitoramento

Como o ambiente √© iniciado "limpo", √© necess√°rio gerar tr√°fego para que as m√©tricas sejam populadas. Siga o fluxo abaixo para validar a observabilidade:

#### 1. Simula√ß√£o de Carga (Gera√ß√£o de Dados)
O Prometheus coleta dados baseados em eventos. Para visualizar gr√°ficos, √© necess√°rio realizar infer√™ncias na API.
1. Acesse o **Swagger UI** (`http://localhost:8000/docs`).
2. Utilize o endpoint `POST /api/predict`.
3. Clique em **Try it out** e depois em **Execute** repetidas vezes (sugere-se 10 a 20 requisi√ß√µes variando ou n√£o os par√¢metros).
   > *Isso gerar√° o hist√≥rico necess√°rio para alimentar os histogramas e contadores de MLOps.*

#### 2. Verifica√ß√£o da Coleta (Prometheus)
Para garantir que a API est√° exportando as m√©tricas corretamente:
1. Acesse o **Prometheus** (`http://localhost:9090`).
2. Na barra de busca, digite a m√©trica de neg√≥cio: `model_last_confidence_score`.
3. Clique em **Execute**.
   > *Se um valor (ex: 0.55) for retornado, a comunica√ß√£o entre os containers est√° ativa.*

#### 3. Visualiza√ß√£o (Grafana)
Para criar ou visualizar os Dashboards de performance:
1. Acesse o **Grafana** (`http://localhost:3000`) e fa√ßa login (`admin`/`admin`).
2. Adicione a fonte de dados (**Data Source**):
   * Selecione **Prometheus**.
   * **Connection URL:** Utilize o endere√ßo interno da rede Docker: `http://prometheus:9090` (N√£o use localhost aqui).
   * Clique em **Save & Test**.
3. Crie um novo Dashboard e adicione pain√©is utilizando as m√©tricas listadas abaixo.

---

### üìä M√©tricas Customizadas de Neg√≥cio

Al√©m das m√©tricas padr√£o de HTTP, o modelo exp√µe as seguintes m√©tricas de MLOps para rastreamento de performance e deriva (Drift):

| M√©trica | Tipo | Descri√ß√£o | Uso no Grafana |
| :--- | :--- | :--- | :--- |
| `model_prediction_price_brl` | **Histogram** | Distribui√ß√£o dos pre√ßos previstos (R$). | Monitorar **Model Drift** (Se a distribui√ß√£o mudar drasticamente, o modelo pode estar descalibrado). |
| `model_last_confidence_score` | **Gauge** | N√≠vel de confian√ßa da √∫ltima infer√™ncia. | Alertar se a confian√ßa m√©dia cair abaixo de um limiar seguro. |
| `model_prediction_direction_total` | **Counter** | Contagem de previs√µes de "Alta" vs "Baixa". | Identificar **Vi√©s (Bias)** do modelo (ex: modelo s√≥ prev√™ alta). |
| `model_input_current_price` | **Gauge** | Pre√ßo real do ativo no momento da requisi√ß√£o. | Comparar em um gr√°fico de linha: *Pre√ßo Real (Input)* vs *Pre√ßo Previsto (Output)*. |


## Conclus√£o

Neste projeto, foi desenvolvida uma solu√ß√£o completa de *Machine Learning* para previs√£o de pre√ßos de a√ß√µes, contemplando todas as etapas do ciclo de vida de um modelo, desde a coleta e prepara√ß√£o dos dados at√© o deploy em uma API funcional.

A utiliza√ß√£o de redes neurais do tipo **LSTM**, aliada a uma engenharia de features robusta e √† modelagem baseada em retorno logar√≠tmico, permitiu capturar padr√µes temporais relevantes em um contexto de alta volatilidade, como o mercado financeiro.

Al√©m do aspecto preditivo, o projeto tamb√©m se preocupa com a **transpar√™ncia e interpretabilidade**, fornecendo ao usu√°rio final indicadores t√©cnicos e macroecon√¥micos que auxiliam na compreens√£o das previs√µes geradas.

Para o futuro, destacam-se a incorpora√ß√£o de novas fontes de dados, o aprimoramento do monitoramento em produ√ß√£o e a avalia√ß√£o cont√≠nua do modelo para adapta√ß√£o a mudan√ßas no regime de mercado.

## üë• Autores

**Turma 6MELT - FIAP**

* Luca Poiti - RM365678
* Gabriel Jordan - RM365606
* Luciana Ferreira - RM366171
* Marcio Lima - RM365919